{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn import metrics\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import *\n",
    "from keras.models import *\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from keras.initializers import *\n",
    "from keras.optimizers import *\n",
    "import keras.backend as K\n",
    "from keras.callbacks import *\n",
    "import tensorflow as tf\n",
    "import os\n",
    "import time\n",
    "import gc\n",
    "import re\n",
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get reproducable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.random import seed\n",
    "from tensorflow import set_random_seed\n",
    "\n",
    "seed(726)\n",
    "set_random_seed(726)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the training and testing files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape :  (256929, 5)\n",
      "Test shape :  (64233, 5)\n"
     ]
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/train_en.tsv\", sep='\\t')\n",
    "test = pd.read_csv(\"data/test_en.tsv\", sep='\\t')\n",
    "\n",
    "print(\"Train shape : \", train.shape)\n",
    "print(\"Test shape : \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>212717</td>\n",
       "      <td>ae5956bd7e744601958008c9514cf1d6</td>\n",
       "      <td>human</td>\n",
       "      <td>male</td>\n",
       "      <td>Mobile usability: have useful help screens htt...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>320629</td>\n",
       "      <td>ff8c26db7278a3b51dba5e5db3f1d1ac</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "      <td>Private VIP Access to Inner-Circle, Top-Secret...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>317601</td>\n",
       "      <td>fdbc9215acb1c676b4592987867c04b8</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "      <td>The Grinch in chief https://t.co/LhUkvXyAfr'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>230018</td>\n",
       "      <td>b9781bb0eebf3143367f245f4fbad019</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "      <td>Grubby Protesters. Not Honest!'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>112325</td>\n",
       "      <td>6586c6858b0aab51410eab76b693714d</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "      <td>A business has to be involving, it has to be f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                id  human  gender  \\\n",
       "0      212717  ae5956bd7e744601958008c9514cf1d6  human    male   \n",
       "1      320629  ff8c26db7278a3b51dba5e5db3f1d1ac  human  female   \n",
       "2      317601  fdbc9215acb1c676b4592987867c04b8  human  female   \n",
       "3      230018  b9781bb0eebf3143367f245f4fbad019    bot     bot   \n",
       "4      112325  6586c6858b0aab51410eab76b693714d    bot     bot   \n",
       "\n",
       "                                               tweet  \n",
       "0  Mobile usability: have useful help screens htt...  \n",
       "1  Private VIP Access to Inner-Circle, Top-Secret...  \n",
       "2       The Grinch in chief https://t.co/LhUkvXyAfr'  \n",
       "3                    Grubby Protesters. Not Honest!'  \n",
       "4  A business has to be involving, it has to be f...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>id</th>\n",
       "      <th>human</th>\n",
       "      <th>gender</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>243250</td>\n",
       "      <td>c32c35b3970fe4cf88df7eb9e3f77719</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "      <td>Check Out this Introduction To http://t.co/zW5...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>267621</td>\n",
       "      <td>d63fb6d001dfc88c4947629dc7243791</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "      <td>Inside Sales Representative: Alro Steel is cur...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>308448</td>\n",
       "      <td>f6ca0df6b6b20238d59395d8340c6c6f</td>\n",
       "      <td>human</td>\n",
       "      <td>female</td>\n",
       "      <td>@meaghano It is good but it’s also kind of wei...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>200213</td>\n",
       "      <td>a47dd96330a9d82cac33b20bc0319366</td>\n",
       "      <td>bot</td>\n",
       "      <td>bot</td>\n",
       "      <td>Great Questions to Ask a Lawyer Prior to Hirin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>293982</td>\n",
       "      <td>eb0ce5669d9adf9aad68880aaba6bcf</td>\n",
       "      <td>human</td>\n",
       "      <td>male</td>\n",
       "      <td>RT @LeeannDempster: On our season ticket sales...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                id  human  gender  \\\n",
       "0      243250  c32c35b3970fe4cf88df7eb9e3f77719    bot     bot   \n",
       "1      267621  d63fb6d001dfc88c4947629dc7243791    bot     bot   \n",
       "2      308448  f6ca0df6b6b20238d59395d8340c6c6f  human  female   \n",
       "3      200213  a47dd96330a9d82cac33b20bc0319366    bot     bot   \n",
       "4      293982   eb0ce5669d9adf9aad68880aaba6bcf  human    male   \n",
       "\n",
       "                                               tweet  \n",
       "0  Check Out this Introduction To http://t.co/zW5...  \n",
       "1  Inside Sales Representative: Alro Steel is cur...  \n",
       "2  @meaghano It is good but it’s also kind of wei...  \n",
       "3  Great Questions to Ask a Lawyer Prior to Hirin...  \n",
       "4  RT @LeeannDempster: On our season ticket sales...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changing case of the tweets to lower case, since the embedding model only has lower case words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"tweet\"] = train[\"tweet\"].str.lower()\n",
    "test[\"tweet\"] = test[\"tweet\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cleaning the puncutation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "puncts = [',', '.', '\"', ':', ')', '(', '-', '!', '?', '|', ';', \"'\", '$', '&', '/', '[', ']', '>', '%', '=', '#', '*', '+', '\\\\', '•',  '~', '@', '£', \n",
    " '·', '_', '{', '}', '©', '^', '®', '`',  '<', '→', '°', '€', '™', '›',  '♥', '←', '×', '§', '″', '′', 'Â', '█', '½', 'à', '…', \n",
    " '“', '★', '”', '–', '●', 'â', '►', '−', '¢', '²', '¬', '░', '¶', '↑', '±', '¿', '▾', '═', '¦', '║', '―', '¥', '▓', '—', '‹', '─', \n",
    " '▒', '：', '¼', '⊕', '▼', '▪', '†', '■', '’', '▀', '¨', '▄', '♫', '☆', 'é', '¯', '♦', '¤', '▲', 'è', '¸', '¾', 'Ã', '⋅', '‘', '∞', \n",
    " '∙', '）', '↓', '、', '│', '（', '»', '，', '♪', '╩', '╚', '³', '・', '╦', '╣', '╔', '╗', '▬', '❤', 'ï', 'Ø', '¹', '≤', '‡', '√', ]\n",
    "\n",
    "def clean_text(x):\n",
    "\n",
    "    x = str(x)\n",
    "    for punct in puncts:\n",
    "        x = x.replace(punct, f' {punct} ')\n",
    "    return x\n",
    "\n",
    "\n",
    "train[\"tweet\"] = train[\"tweet\"].apply(lambda x: clean_text(x))\n",
    "test[\"tweet\"] = test[\"tweet\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "visualize word distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tharindu/anaconda3/envs/sentence_similarity_3.6/lib/python3.6/site-packages/scipy/stats/stats.py:1713: FutureWarning: Using a non-tuple sequence for multidimensional indexing is deprecated; use `arr[tuple(seq)]` instead of `arr[seq]`. In the future this will be interpreted as an array index, `arr[np.array(seq)]`, which will result either in an error or a different result.\n",
      "  return np.add.reduce(sorted[indexer] * weights, axis=axis) / sumval\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "train['doc_len'] = train[\"tweet\"].apply(lambda words: len(words.split(\" \")))\n",
    "max_seq_len = np.round(train['doc_len'].mean() + train['doc_len'].std()).astype(int)\n",
    "sns.distplot(train['doc_len'], hist=True, kde=True, color='b', label='doc len')\n",
    "plt.axvline(x=max_seq_len, color='k', linestyle='--', label='max len')\n",
    "plt.title('tweet length'); plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape :  (64233, 5)\n"
     ]
    }
   ],
   "source": [
    "## some config values \n",
    "embed_size = 300 # how big is each word vector\n",
    "max_features = None # how many unique words to use (i.e num rows in embedding vector)\n",
    "maxlen = max_seq_len # max number of words in a question to use #99.99%\n",
    "\n",
    "## fill up the missing values\n",
    "X = train[\"tweet\"].fillna(\"_na_\").values\n",
    "print(\"Test shape : \", test.shape)\n",
    "X_test = test[\"tweet\"].fillna(\"_na_\").values\n",
    "\n",
    "## Tokenize the sentences\n",
    "tokenizer = Tokenizer(num_words=max_features, filters='')\n",
    "tokenizer.fit_on_texts(list(X))\n",
    "\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "## Pad the sentences \n",
    "X = pad_sequences(X, maxlen=maxlen)\n",
    "X_test = pad_sequences(X_test, maxlen=maxlen)\n",
    "\n",
    "## Get the target values\n",
    "Y = train['human'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "bot      132940\n",
       "human    123989\n",
       "Name: human, dtype: int64"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.human.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 1, 0])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "\n",
    "le.fit(Y)\n",
    "encoded_Y = le.transform(Y)\n",
    "encoded_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Embedding matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tokenizer.word_index\n",
    "max_features = len(word_index)+1\n",
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '/data/glove/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if o.split(\" \")[0] in word_index)\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix \n",
    "    \n",
    "def load_fasttext(word_index):    \n",
    "    EMBEDDING_FILE = '/data/fasttext/crawl-300d-2M-subword.vec'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE) if len(o)>100 and o.split(\" \")[0] in word_index )\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (max_features, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "\n",
    "    return embedding_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Only Glove vectors have been used in embedding matrix. Can explore it further in future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tharindu/anaconda3/envs/sentence_similarity_3.6/lib/python3.6/site-packages/ipykernel_launcher.py:25: FutureWarning: arrays to stack must be passed as a \"sequence\" type such as list or tuple. Support for non-sequence iterables such as generators is deprecated as of NumPy 1.16 and will raise an error in the future.\n"
     ]
    }
   ],
   "source": [
    "embedding_matrix = load_fasttext(word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definning the Capsule Layer in Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def squash(x, axis=-1):\n",
    "    s_squared_norm = K.sum(K.square(x), axis, keepdims=True)\n",
    "    scale = K.sqrt(s_squared_norm + K.epsilon())\n",
    "    return x / scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Capsule(Layer):\n",
    "    def __init__(self, num_capsule, dim_capsule, routings=3, kernel_size=(9, 1), share_weights=True,\n",
    "                 activation='default', **kwargs):\n",
    "        super(Capsule, self).__init__(**kwargs)\n",
    "        self.num_capsule = num_capsule\n",
    "        self.dim_capsule = dim_capsule\n",
    "        self.routings = routings\n",
    "        self.kernel_size = kernel_size\n",
    "        self.share_weights = share_weights\n",
    "        if activation == 'default':\n",
    "            self.activation = squash\n",
    "        else:\n",
    "            self.activation = Activation(activation)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        super(Capsule, self).build(input_shape)\n",
    "        input_dim_capsule = input_shape[-1]\n",
    "        if self.share_weights:\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(1, input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     # shape=self.kernel_size,\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "        else:\n",
    "            input_num_capsule = input_shape[-2]\n",
    "            self.W = self.add_weight(name='capsule_kernel',\n",
    "                                     shape=(input_num_capsule,\n",
    "                                            input_dim_capsule,\n",
    "                                            self.num_capsule * self.dim_capsule),\n",
    "                                     initializer='glorot_uniform',\n",
    "                                     trainable=True)\n",
    "            \n",
    "    def call(self, u_vecs):\n",
    "        if self.share_weights:\n",
    "            u_hat_vecs = K.conv1d(u_vecs, self.W)\n",
    "        else:\n",
    "            u_hat_vecs = K.local_conv1d(u_vecs, self.W, [1], [1])\n",
    "\n",
    "        batch_size = K.shape(u_vecs)[0]\n",
    "        input_num_capsule = K.shape(u_vecs)[1]\n",
    "        u_hat_vecs = K.reshape(u_hat_vecs, (batch_size, input_num_capsule, self.num_capsule, self.dim_capsule))\n",
    "        u_hat_vecs = K.permute_dimensions(u_hat_vecs, (0, 2, 1, 3))\n",
    "        # final u_hat_vecs.shape = [None, num_capsule, input_num_capsule, dim_capsule]\n",
    "\n",
    "        b = K.zeros_like(u_hat_vecs[:, :, :, 0])  # shape = [None, num_capsule, input_num_capsule]\n",
    "        for i in range(self.routings):\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))  # shape = [None, input_num_capsule, num_capsule]\n",
    "            c = K.softmax(b)\n",
    "            c = K.permute_dimensions(c, (0, 2, 1))\n",
    "            b = K.permute_dimensions(b, (0, 2, 1))\n",
    "            outputs = self.activation(K.batch_dot(c, u_hat_vecs, [2, 2]))\n",
    "            if i < self.routings - 1:\n",
    "                b = K.batch_dot(outputs, u_hat_vecs, [2, 3])\n",
    "\n",
    "        return outputs\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (None, self.num_capsule, self.dim_capsule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Capsule Layer with a Bi directional GRU. Architecture found in text classification project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def capsule():\n",
    "    K.clear_session()       \n",
    "    inp = Input(shape=(maxlen,))\n",
    "    x = Embedding(max_features, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = SpatialDropout1D(rate=0.2)(x)\n",
    "    x = Bidirectional(GRU(100, return_sequences=True, \n",
    "                                kernel_initializer=glorot_normal(seed=12300), recurrent_initializer=orthogonal(gain=1.0, seed=10000)))(x)\n",
    "\n",
    "    x = Capsule(num_capsule=10, dim_capsule=10, routings=4, share_weights=True)(x)\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    x = Dense(100, activation=\"relu\", kernel_initializer=glorot_normal(seed=12300))(x)\n",
    "    x = Dropout(0.12)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = Dense(1, activation=\"sigmoid\")(x)\n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(),)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1_smart(y_true, y_pred):\n",
    "    args = np.argsort(y_pred)\n",
    "    tp = y_true.sum()\n",
    "    fs = (tp - np.cumsum(y_true[args[:-1]])) / np.arange(y_true.shape[0] + tp - 1, tp, -1)\n",
    "    res_idx = np.argmax(fs)\n",
    "    return 2 * fs[res_idx], (y_pred[args[res_idx]] + y_pred[args[res_idx + 1]]) / 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with early stopping and reducing learning rate on plateu. In each fold values for the test set is also predicted, And after the process, predicted values for the test file would be mean from each fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 85)                0         \n",
      "_________________________________________________________________\n",
      "embedding_1 (Embedding)      (None, 85, 300)           116578200 \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 85, 300)           0         \n",
      "_________________________________________________________________\n",
      "bidirectional_1 (Bidirection (None, 85, 200)           240600    \n",
      "_________________________________________________________________\n",
      "capsule_1 (Capsule)          (None, 10, 10)            20000     \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 116,849,401\n",
      "Trainable params: 271,001\n",
      "Non-trainable params: 116,578,400\n",
      "_________________________________________________________________\n",
      "None\n",
      "Train on 205543 samples, validate on 51386 samples\n",
      "Epoch 1/6\n",
      " - 233s - loss: 0.2935 - val_loss: 0.1959\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19586, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 2/6\n",
      " - 234s - loss: 0.1961 - val_loss: 0.1642\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19586 to 0.16417, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 3/6\n",
      " - 234s - loss: 0.1684 - val_loss: 0.1514\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16417 to 0.15143, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 4/6\n",
      " - 228s - loss: 0.1488 - val_loss: 0.1404\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15143 to 0.14041, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 5/6\n",
      " - 231s - loss: 0.1350 - val_loss: 0.1382\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.14041 to 0.13818, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 6/6\n",
      " - 231s - loss: 0.1229 - val_loss: 0.1264\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.13818 to 0.12640, saving model to models/capsule_net_weights_best.h5\n",
      "Optimal F1: 0.9569 at threshold: 0.6170\n",
      "Train on 205543 samples, validate on 51386 samples\n",
      "Epoch 1/6\n",
      " - 232s - loss: 0.2834 - val_loss: 0.2331\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.23307, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 2/6\n",
      " - 230s - loss: 0.1906 - val_loss: 0.1670\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.23307 to 0.16696, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 3/6\n",
      " - 227s - loss: 0.1632 - val_loss: 0.1527\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16696 to 0.15273, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 4/6\n",
      " - 230s - loss: 0.1448 - val_loss: 0.1344\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.15273 to 0.13437, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 5/6\n",
      " - 231s - loss: 0.1320 - val_loss: 0.1438\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.13437\n",
      "\n",
      "Epoch 00005: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 6/6\n",
      " - 231s - loss: 0.1144 - val_loss: 0.1203\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.13437 to 0.12033, saving model to models/capsule_net_weights_best.h5\n",
      "Optimal F1: 0.9577 at threshold: 0.4731\n",
      "Train on 205543 samples, validate on 51386 samples\n",
      "Epoch 1/6\n",
      " - 234s - loss: 0.2856 - val_loss: 0.1940\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19399, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 2/6\n",
      " - 228s - loss: 0.1893 - val_loss: 0.1585\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19399 to 0.15850, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 3/6\n",
      " - 229s - loss: 0.1635 - val_loss: 0.1428\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.15850 to 0.14278, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 4/6\n",
      " - 229s - loss: 0.1481 - val_loss: 0.1377\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.14278 to 0.13770, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 5/6\n",
      " - 227s - loss: 0.1339 - val_loss: 0.1362\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.13770 to 0.13615, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 6/6\n",
      " - 229s - loss: 0.1251 - val_loss: 0.1245\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.13615 to 0.12448, saving model to models/capsule_net_weights_best.h5\n",
      "Optimal F1: 0.9559 at threshold: 0.3190\n",
      "Train on 205543 samples, validate on 51386 samples\n",
      "Epoch 1/6\n",
      " - 230s - loss: 0.2877 - val_loss: 0.1982\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.19815, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 2/6\n",
      " - 231s - loss: 0.1972 - val_loss: 0.1650\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.19815 to 0.16497, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 3/6\n",
      " - 228s - loss: 0.1658 - val_loss: 0.1739\n",
      "\n",
      "Epoch 00003: val_loss did not improve from 0.16497\n",
      "\n",
      "Epoch 00003: ReduceLROnPlateau reducing learning rate to 0.0006000000284984708.\n",
      "Epoch 4/6\n",
      " - 229s - loss: 0.1442 - val_loss: 0.1427\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.16497 to 0.14269, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 5/6\n",
      " - 228s - loss: 0.1330 - val_loss: 0.1271\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.14269 to 0.12709, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 6/6\n",
      " - 231s - loss: 0.1234 - val_loss: 0.1252\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12709 to 0.12524, saving model to models/capsule_net_weights_best.h5\n",
      "Optimal F1: 0.9563 at threshold: 0.3910\n",
      "Train on 205544 samples, validate on 51385 samples\n",
      "Epoch 1/6\n",
      " - 230s - loss: 0.2850 - val_loss: 0.2015\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.20152, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 2/6\n",
      " - 228s - loss: 0.1920 - val_loss: 0.1670\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.20152 to 0.16700, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 3/6\n",
      " - 228s - loss: 0.1626 - val_loss: 0.1461\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.16700 to 0.14610, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 4/6\n",
      " - 230s - loss: 0.1453 - val_loss: 0.1368\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.14610 to 0.13681, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 5/6\n",
      " - 228s - loss: 0.1323 - val_loss: 0.1303\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.13681 to 0.13028, saving model to models/capsule_net_weights_best.h5\n",
      "Epoch 6/6\n",
      " - 231s - loss: 0.1219 - val_loss: 0.1261\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.13028 to 0.12611, saving model to models/capsule_net_weights_best.h5\n",
      "Optimal F1: 0.9553 at threshold: 0.4182\n"
     ]
    }
   ],
   "source": [
    "kfold = StratifiedKFold(n_splits=5, random_state=10, shuffle=True)\n",
    "bestscore = []\n",
    "y_test = np.zeros((X_test.shape[0], ))\n",
    "for i, (train_index, valid_index) in enumerate(kfold.split(X, encoded_Y)):\n",
    "    X_train, X_val, Y_train, Y_val = X[train_index], X[valid_index], encoded_Y[train_index], encoded_Y[valid_index]\n",
    "    filepath=\"models/capsule_net_weights_best.h5\"\n",
    "    checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=2, save_best_only=True, mode='min')\n",
    "    reduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.6, patience=1, min_lr=0.0001, verbose=2)\n",
    "    earlystopping = EarlyStopping(monitor='val_loss', min_delta=0.0001, patience=2, verbose=2, mode='auto')\n",
    "    callbacks = [checkpoint, reduce_lr]\n",
    "    model = capsule()\n",
    "    if i == 0:print(model.summary()) \n",
    "    model.fit(X_train, Y_train, batch_size=64, epochs=6, validation_data=(X_val, Y_val), verbose=2, callbacks=callbacks, \n",
    "             )\n",
    "    model.load_weights(filepath)\n",
    "    y_pred = model.predict([X_val], batch_size=64, verbose=2)\n",
    "    y_test += np.squeeze(model.predict([X_test], batch_size=64, verbose=2))/5\n",
    "    f1, threshold = f1_smart(np.squeeze(Y_val), np.squeeze(y_pred))\n",
    "    print('Optimal F1: {:.4f} at threshold: {:.4f}'.format(f1, threshold))\n",
    "    bestscore.append(threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting the predictions for integer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tharindu/anaconda3/envs/sentence_similarity_3.6/lib/python3.6/site-packages/sklearn/preprocessing/label.py:273: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "y_test = y_test.reshape((-1, 1))\n",
    "pred_test_y = (y_test>np.mean(bestscore)).astype(int)\n",
    "test['predictions'] = le.inverse_transform(pred_test_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31565, 1889, 779, 30000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "tn, fp, fn, tp = confusion_matrix(test[\"human\"], test['predictions']).ravel()\n",
    "(tn, fp, fn, tp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9584637180265596"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(test[\"human\"], test['predictions'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:sentence_similarity_3.6]",
   "language": "python",
   "name": "conda-env-sentence_similarity_3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
